{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6y23yCuMBwj",
    "tags": []
   },
   "source": [
    "## DeiT Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uKiaXIRuMBwn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pip install wandb -qU\n",
    "%matplotlib inline\n",
    "\n",
    "# Get the current working directory\n",
    "notebook_dir = notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))  \n",
    "project_dir = os.path.abspath(os.path.join(notebook_dir, '..')) \n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "from src import (get_transforms, load_data, split_data, set_seeds, \n",
    "                 verify_splits, verify_data, plot_species_grid,\n",
    "                 verify_loader_transforms)\n",
    "from src.data_utils import ImagesDataset, get_transforms_transformer\n",
    "from src.models import build_efficientnet_v2_basic, build_deit_model, build_swin_model\n",
    "from src.train import setup_training, evaluate_deit, train_deit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sympy==1.13.1 in /Users/evaball/opt/miniconda3/envs/dlfinal/lib/python3.12/site-packages (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/evaball/opt/miniconda3/envs/dlfinal/lib/python3.12/site-packages (from sympy==1.13.1) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sympy==1.13.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/evaball/opt/miniconda3/envs/dlfinal/lib/python3.12/site-packages (4.47.0)\n",
      "Requirement already satisfied: filelock in /Users/evaball/opt/miniconda3/envs/dlfinal/lib/python3.12/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Users/evaball/opt/miniconda3/envs/dlfinal/lib/python3.12/site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/evaball/opt/miniconda3/envs/dlfinal/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/evaball/opt/miniconda3/envs/dlfinal/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/evaball/opt/miniconda3/envs/dlfinal/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/evaball/opt/miniconda3/envs/dlfinal/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/evaball/opt/miniconda3/envs/dlfinal/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/evaball/opt/miniconda3/envs/dlfinal/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/evaball/opt/miniconda3/envs/dlfinal/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/evaball/opt/miniconda3/envs/dlfinal/lib/python3.12/site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/evaball/opt/miniconda3/envs/dlfinal/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/evaball/opt/miniconda3/envs/dlfinal/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/evaball/opt/miniconda3/envs/dlfinal/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/evaball/opt/miniconda3/envs/dlfinal/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/evaball/opt/miniconda3/envs/dlfinal/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/evaball/opt/miniconda3/envs/dlfinal/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Set up your experiment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy this notebook. Rename it, but keep it in `notebooks/`. To update any settings, params, and/or hyperparams make a copy of `configs/default.yaml`, rename it and call your new `.yaml` below. Be sure to keep it in `configs/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the YAML file relative to the notebook's location\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "# You need to update this path to your new .yaml file\n",
    "config_path = os.path.join(notebook_dir, \"../configs/deit.yaml\")\n",
    "\n",
    "# Load the YAML file\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.backends.mps.is_available())\n",
    "device = config[\"device\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Build the datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data\n",
    "Note: your data file should be hidden in the repo (.gitignore) but make sure to set it up locally like:\n",
    "\n",
    "`wildlife/data/givens/test_features/[images...]`\n",
    "\n",
    "`wildlife/data/givens/train_features/[images...]`\n",
    "\n",
    "`wildlife/data/givens/train_features.csv`\n",
    "\n",
    "`wildlife/data/givens/test_features.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_features, test_features, train_labels, species_labels = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=[224, 224], interpolation=bilinear, max_size=None, antialias=True)\n",
      "    Lambda()\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2), hue=(-0.1, 0.1))\n",
      "    ToTensor()\n",
      ")\n",
      "Compose(\n",
      "    Resize(size=[224, 224], interpolation=bilinear, max_size=None, antialias=True)\n",
      "    Lambda()\n",
      "    ToTensor()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get transforms\n",
    "train_transforms, val_transforms = get_transforms_transformer(config)\n",
    "print(train_transforms)\n",
    "print(val_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNzMhcTGMBwp"
   },
   "source": [
    "#### Split into train and evaluation sets\n",
    "\n",
    "We need to ensure that sites are mutually exclusive between the training and validation sets, meaning no site should appear in both sets. This ensures a proper stratification based on site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(config[\"experiment\"][\"seed\"])\n",
    "X_train, X_val, y_train, y_val = split_data(\n",
    "    train_features, train_labels, type='sites')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function (Optional)\n",
    "# verify_splits(X_train, y_train, X_val,  y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Count the number of samples for each class in the training set\n",
    "# class_counts = y_train.sum(axis=0)  # Sum column-wise to get the count for each class\n",
    "\n",
    "# # Convert to a dictionary for visualization\n",
    "# class_counts_dict = class_counts.to_dict()\n",
    "\n",
    "# # Sort class counts in descending order and retain both labels and counts\n",
    "# sorted_counts = sorted(class_counts_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# # Extract class labels and counts separately after sorting\n",
    "# labels, counts = zip(*sorted_counts)\n",
    "\n",
    "# # Plot the distribution\n",
    "# plt.figure(figsize=(7, 6))\n",
    "# plt.bar(labels, counts, edgecolor='black', color='skyblue')\n",
    "# plt.xlabel(\"Class Labels\")\n",
    "# plt.ylabel(\"Number of Samples\")\n",
    "# plt.title(\"Training Data Distribution\")\n",
    "# plt.xticks(rotation=45, ha=\"right\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify transformations in dataloaders (Optional)\n",
    "# verify_loader_transforms(train_loader, title_type='train')\n",
    "# verify_loader_transforms(val_loader, title_type='validate')\n",
    "\n",
    "# set_seeds(config[\"experiment\"]['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPwe5YFjMBwv",
    "tags": []
   },
   "source": [
    "### **Training**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model\n",
    "Note: If you build a new model, add it to `models.py` and update the block below. And update your `.yaml` config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_seeds(config[\"experiment\"]['seed'])\n",
    "# model = build_resnet50_basic(\n",
    "#     num_classes = config[\"model\"][\"num_classes\"],\n",
    "#     hidden_units1 = config[\"model\"][\"hidden_units1\"],\n",
    "#     dropout = config[\"model\"][\"dropout\"],\n",
    "#     freeze_backbone = config[\"model\"][\"freeze_backbone\"]\n",
    "# )\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evaball/opt/miniconda3/envs/dlfinal/lib/python3.12/site-packages/transformers/models/deit/feature_extraction_deit.py:28: FutureWarning: The class DeiTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use DeiTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Some weights of DeiTForImageClassification were not initialized from the model checkpoint at facebook/deit-base-distilled-patch16-224 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "set_seeds(config[\"experiment\"]['seed'])\n",
    "feature_extractor, model =  build_deit_model(\n",
    "    num_classes = config[\"model\"][\"num_classes\"],\n",
    "    dropout = config[\"model\"][\"dropout\"],\n",
    "    hidden_units1=config[\"model\"][\"hidden_units1\"],\n",
    "    freeze_backbone = config[\"model\"][\"freeze_backbone\"]\n",
    ")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_seeds(config[\"experiment\"]['seed'])\n",
    "# feature_extractor, model =  build_swin_model(\n",
    "#     num_classes = config[\"model\"][\"num_classes\"],\n",
    "#     dropout = config[\"model\"][\"dropout\"],\n",
    "#     freeze_backbone = config[\"model\"][\"freeze_backbone\"]\n",
    "# )\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define your criterion and optimizer\n",
    "Note: If needed up date these in `train.py` and update your `.yaml` config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yf3bCjmwMBwv",
    "outputId": "e0b47689-3576-4c08-c1f8-fb4515032200"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.02\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "set_seeds(config[\"experiment\"]['seed'])\n",
    "class_counts = y_train.sum(axis=0).values\n",
    "# print(class_counts)\n",
    "\n",
    "criterion, optimizer = setup_training(\n",
    "        model, \n",
    "        criterion=config[\"train\"][\"criterion\"],\n",
    "        optimizer=config[\"train\"][\"optimizer\"], \n",
    "        lr=config[\"train\"][\"lr\"], \n",
    "        momentum=config[\"train\"][\"momentum\"],\n",
    "        gamma=config[\"train\"][\"gamma\"],\n",
    "        alpha=config[\"train\"][\"alpha\"],\n",
    "        device=device,\n",
    "        weight_decay=config[\"train\"][\"weight_decay\"],\n",
    "        cls_num_list=class_counts)\n",
    "# print(config[\"train\"][\"alpha\"])\n",
    "print(optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class distribution and difficulty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(config[\"experiment\"][\"seed\"])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ImagesDataset(\n",
    "    features=X_train, \n",
    "    labels=y_train, \n",
    "    feature_extractor=feature_extractor, \n",
    "    transform=train_transforms,\n",
    "    device=device)\n",
    "val_dataset = ImagesDataset(\n",
    "    features=X_val, \n",
    "    labels=y_val, \n",
    "    feature_extractor=feature_extractor, \n",
    "    transform=val_transforms,\n",
    "    device=device)\n",
    "\n",
    "# # Create datasets\n",
    "# train_dataset = ImagesDataset(\n",
    "#     features=X_train, \n",
    "#     labels=y_train, \n",
    "#     device=device)\n",
    "# val_dataset = ImagesDataset(\n",
    "#     features=X_val, \n",
    "#     labels=y_val, \n",
    "#     device=device)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config[\"train\"][\"batch_size\"], \n",
    "    shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=config[\"train\"][\"batch_size\"], \n",
    "    shuffle=False, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 13171 samples\n",
      "Validation set: 3317 samples\n"
     ]
    }
   ],
   "source": [
    "# Print shapes for verification (Optional)\n",
    "print(f\"Training set: {len(train_dataset)} samples\")\n",
    "print(f\"Validation set: {len(val_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgball30\u001b[0m (\u001b[33mgball30-georgia-institute-of-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.require()\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/evaball/Documents/CS_Projects/HomeWork/Gatech/wildlife/notebooks/wandb/run-20241210_052644-ir0nmpea</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gball30-georgia-institute-of-technology/wildlife/runs/ir0nmpea' target=\"_blank\">bumbling-feather-218</a></strong> to <a href='https://wandb.ai/gball30-georgia-institute-of-technology/wildlife' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gball30-georgia-institute-of-technology/wildlife' target=\"_blank\">https://wandb.ai/gball30-georgia-institute-of-technology/wildlife</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gball30-georgia-institute-of-technology/wildlife/runs/ir0nmpea' target=\"_blank\">https://wandb.ai/gball30-georgia-institute-of-technology/wildlife/runs/ir0nmpea</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/gball30-georgia-institute-of-technology/wildlife/runs/ir0nmpea?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x325521e80>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ✨ W&B: Initialize a new run to track this model's training\n",
    "wandb.init(project=\"wildlife\", config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the train / eval loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for epoch 1\n",
      "Epoch [1/2], Step [100/1647], Loss: 0.389050543308\n",
      "Epoch [1/2], Step [200/1647], Loss: 0.405633449554\n",
      "Epoch [1/2], Step [300/1647], Loss: 0.667836904526\n",
      "Epoch [1/2], Step [400/1647], Loss: 0.477503061295\n",
      "Epoch [1/2], Step [500/1647], Loss: 0.582152843475\n",
      "Epoch [1/2], Step [600/1647], Loss: 0.571086585522\n",
      "Epoch [1/2], Step [700/1647], Loss: 0.456843793392\n",
      "Epoch [1/2], Step [800/1647], Loss: 0.968188703060\n",
      "Epoch [1/2], Step [900/1647], Loss: 0.480322122574\n",
      "Epoch [1/2], Step [1000/1647], Loss: 0.527938961983\n",
      "Epoch [1/2], Step [1100/1647], Loss: 0.297837883234\n",
      "Epoch [1/2], Step [1200/1647], Loss: 0.393239289522\n",
      "Epoch [1/2], Step [1300/1647], Loss: 0.150353491306\n",
      "Epoch [1/2], Step [1400/1647], Loss: 0.432737767696\n",
      "Epoch [1/2], Step [1500/1647], Loss: 0.358301520348\n",
      "Epoch [1/2], Step [1600/1647], Loss: 0.267841279507\n",
      "Epoch 1/2 - Avg Train Loss: 0.479236056552\n",
      "Eval - Loss: 0.8443, Accuracy: 40.82%, Precision: 0.49, Recall: 0.41, F1: 0.37, MacroF1: 0.37\n",
      "Epoch 1/2 - Eval Loss: 0.844298551743, Eval Acc: 40.82%\n",
      "Starting training for epoch 2\n",
      "Epoch [2/2], Step [100/1647], Loss: 0.386910736561\n",
      "Epoch [2/2], Step [200/1647], Loss: 0.781336784363\n",
      "Epoch [2/2], Step [300/1647], Loss: 0.698809444904\n",
      "Epoch [2/2], Step [400/1647], Loss: 0.282350122929\n",
      "Epoch [2/2], Step [500/1647], Loss: 0.287197947502\n",
      "Epoch [2/2], Step [600/1647], Loss: 0.841446816921\n",
      "Epoch [2/2], Step [700/1647], Loss: 0.641168117523\n",
      "Epoch [2/2], Step [800/1647], Loss: 0.225026756525\n",
      "Epoch [2/2], Step [900/1647], Loss: 0.250323265791\n",
      "Epoch [2/2], Step [1000/1647], Loss: 0.857637047768\n",
      "Epoch [2/2], Step [1100/1647], Loss: 0.543211817741\n",
      "Epoch [2/2], Step [1200/1647], Loss: 0.740851223469\n",
      "Epoch [2/2], Step [1300/1647], Loss: 0.546745896339\n",
      "Epoch [2/2], Step [1400/1647], Loss: 0.219771146774\n",
      "Epoch [2/2], Step [1500/1647], Loss: 0.293131351471\n",
      "Epoch [2/2], Step [1600/1647], Loss: 0.326806575060\n",
      "Epoch 2/2 - Avg Train Loss: 0.462358930053\n",
      "Eval - Loss: 0.7305, Accuracy: 44.68%, Precision: 0.46, Recall: 0.45, F1: 0.43, MacroF1: 0.43\n",
      "Epoch 2/2 - Eval Loss: 0.730512826881, Eval Acc: 44.68%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_losses = []  # To store average training loss per epoch\n",
    "val_losses = []    # To store validation loss per epoch\n",
    "set_seeds(config[\"experiment\"]['seed'])\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(config[\"train\"][\"epochs\"]):\n",
    "# for epoch in range(2):\n",
    "    # Training step\n",
    "    avg_train_loss = train_deit(\n",
    "        model, \n",
    "        train_loader, criterion, optimizer, \n",
    "        epoch, config, device=device)\n",
    "    train_losses.append(avg_train_loss)  # Store avg training loss\n",
    "    print(f\"Epoch {epoch+1}/{config[\"train\"][\"epochs\"]} - Avg Train Loss: {\n",
    "        avg_train_loss:.12f}\")\n",
    "    \n",
    "    # Evaluation step\n",
    "    eval_metrics = evaluate_deit(\n",
    "        model, val_loader, criterion, \n",
    "        config, epoch+1, device=device)\n",
    "    val_losses.append(eval_metrics[\"loss\"])  # Store validation loss\n",
    "    print(f\"Epoch {epoch+1}/{config[\"train\"][\"epochs\"]} - Eval Loss: {\n",
    "        eval_metrics['loss']:.12f}, Eval Acc: {eval_metrics['accuracy']:.2f}%\")\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "wandb.log({\"duration\": duration})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are done logging or you want to run the experiment again, finish with the block below. But if you think you might want to submit this run to the competition, don't finish logging until the end once you've added the competition score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>duration</td><td>█▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁█████▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████</td></tr><tr><td>eval_accuracy</td><td>▁█▅█</td></tr><tr><td>eval_f1</td><td>▁█▄█</td></tr><tr><td>eval_loss</td><td>█▃▆▁</td></tr><tr><td>eval_macro_f1</td><td>▁█▄█</td></tr><tr><td>eval_precision</td><td>█▅▆▁</td></tr><tr><td>eval_recall</td><td>▁█▅█</td></tr><tr><td>f1_antelope_duiker</td><td>▅█▇▁</td></tr><tr><td>f1_bird</td><td>▁▁█▃</td></tr><tr><td>f1_blank</td><td>▁█▁█</td></tr><tr><td>f1_civet_genet</td><td>▁▅█▅</td></tr><tr><td>f1_hog</td><td>▁▅██</td></tr><tr><td>f1_leopard</td><td>▁█▂▅</td></tr><tr><td>f1_macro avg</td><td>▁█▄█</td></tr><tr><td>f1_monkey_prosimian</td><td>▁▆▆█</td></tr><tr><td>f1_rodent</td><td>▁█▂█</td></tr><tr><td>f1_weighted avg</td><td>▁█▄█</td></tr><tr><td>loss</td><td>▆▄▂▇▁█▅▁▃▃▃▂▄▁▄▅█▂▂▄▂▃▄▅▄▃▃▂▅▇█▁▂▁▃▅▇▇▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>duration</td><td>761.86389</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>eval_accuracy</td><td>44.67893</td></tr><tr><td>eval_f1</td><td>0.43295</td></tr><tr><td>eval_loss</td><td>0.73051</td></tr><tr><td>eval_macro_f1</td><td>0.42902</td></tr><tr><td>eval_precision</td><td>0.4612</td></tr><tr><td>eval_recall</td><td>0.44679</td></tr><tr><td>f1_antelope_duiker</td><td>0.35228</td></tr><tr><td>f1_bird</td><td>0.14</td></tr><tr><td>f1_blank</td><td>0.35611</td></tr><tr><td>f1_civet_genet</td><td>0.46397</td></tr><tr><td>f1_hog</td><td>0.49434</td></tr><tr><td>f1_leopard</td><td>0.57803</td></tr><tr><td>f1_macro avg</td><td>0.42902</td></tr><tr><td>f1_monkey_prosimian</td><td>0.53165</td></tr><tr><td>f1_rodent</td><td>0.51579</td></tr><tr><td>f1_weighted avg</td><td>0.43295</td></tr><tr><td>loss</td><td>0.32681</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bumbling-feather-218</strong> at: <a href='https://wandb.ai/gball30-georgia-institute-of-technology/wildlife/runs/ir0nmpea' target=\"_blank\">https://wandb.ai/gball30-georgia-institute-of-technology/wildlife/runs/ir0nmpea</a><br/> View project at: <a href='https://wandb.ai/gball30-georgia-institute-of-technology/wildlife' target=\"_blank\">https://wandb.ai/gball30-georgia-institute-of-technology/wildlife</a><br/>Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 4 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241210_052644-ir0nmpea/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ✨ W&B: Mark the run as complete (Or wait until the end of notebook)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Explore Experiment** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to True to explore and potentially submit your results \n",
    "explore = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if explore:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, config[\"train\"][\"epochs\"]+1), train_losses, label=\"Training Loss\", marker=\"o\")\n",
    "    plt.plot(range(1, config[\"train\"][\"epochs\"]+1), val_losses, label=\"Validation Loss\", marker=\"o\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Distribution  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Labels from Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if explore:\n",
    "    print(\"True labels (training):\")\n",
    "    print(y_train.idxmax(axis=1).value_counts())   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True and Predicated Labels from Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if explore:\n",
    "    # Extract predictions and true labels from eval_metrics\n",
    "    all_preds = eval_metrics[\"all_preds\"]\n",
    "    all_labels = eval_metrics[\"all_labels\"]\n",
    "\n",
    "    # Convert all_preds to DataFrame and map to class names\n",
    "    preds_df = pd.DataFrame(all_preds, columns=[\"predicted_class\"])\n",
    "    preds_df[\"predicted_label\"] = preds_df[\"predicted_class\"].map(\n",
    "        lambda idx: species_labels[idx]\n",
    "    )\n",
    "\n",
    "    # Convert all_labels to DataFrame and map to class names\n",
    "    labels_df = pd.DataFrame(all_labels, columns=[\"true_class\"])\n",
    "    labels_df[\"true_label\"] = labels_df[\"true_class\"].map(\n",
    "        lambda idx: species_labels[idx]\n",
    "    )\n",
    "\n",
    "    # Combine predictions and true labels for analysis\n",
    "    results_df = pd.concat([preds_df, labels_df], axis=1)\n",
    "\n",
    "    # Display value counts for predicted and true labels\n",
    "    print(\"Predicted labels (eval):\")\n",
    "    print(results_df[\"predicted_label\"].value_counts())\n",
    "\n",
    "    print(\"\\nTrue labels (eval):\")\n",
    "    print(results_df[\"true_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if explore:    \n",
    "    per_class_accuracy = results_df.groupby(\"true_label\").apply(\n",
    "        lambda x: (x[\"true_label\"] == x[\"predicted_label\"]).mean(), \n",
    "    )\n",
    "    print(\"Per-Class Accuracy:\")\n",
    "    print(per_class_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if explore:\n",
    "    from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "    eval_true = pd.Series(all_labels).apply(lambda x: species_labels[x])\n",
    "    eval_predictions = pd.Series(all_preds).apply(lambda x: species_labels[x])\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    cm = ConfusionMatrixDisplay.from_predictions(\n",
    "        eval_true,\n",
    "        eval_predictions,\n",
    "        ax=ax,\n",
    "        xticks_rotation=90,\n",
    "        colorbar=True,\n",
    "        normalize='true'\n",
    "    )\n",
    "    plt.title(\"Normalized Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create Submission**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Datatloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if explore:\n",
    "    set_seeds(config[\"experiment\"][\"seed\"])\n",
    "    test_dataset = ImagesDataset(\n",
    "        test_features, \n",
    "        device=device)\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=config[\"train\"][\"batch_size\"], \n",
    "        shuffle=False, pin_memory=True)\n",
    "    \n",
    "    print(f\"Test set: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if explore:\n",
    "    test_preds_collector = []\n",
    "\n",
    "    # put the model in eval mode so we don't update any parameters\n",
    "    model.eval()\n",
    "\n",
    "    # we aren't updating our weights so no need to calculate gradients\n",
    "    with torch.no_grad():\n",
    "        for batch_n, batch in enumerate(test_loader):\n",
    "            # run the forward step\n",
    "            images = batch[\"image\"].to(device)\n",
    "            logits = model(images)\n",
    "\n",
    "            # apply softmax so that model outputs are in range [0,1]\n",
    "            preds = F.softmax(logits, dim=1)\n",
    "\n",
    "            # store this batch's predictions in df\n",
    "            # note that PyTorch Tensors need to first be detached from their computational graph before converting to numpy arrays\n",
    "            preds_df = pd.DataFrame(\n",
    "                preds.cpu().numpy(),\n",
    "                index=batch[\"image_id\"],\n",
    "                columns=species_labels,\n",
    "            )\n",
    "            test_preds_collector.append(preds_df)\n",
    "\n",
    "    submission_df = pd.concat(test_preds_collector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your submission. Update submission_number.\n",
    "\n",
    "Make sure your directory is properly set up, as both `/data` and `/results` are ignored by the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if explore:\n",
    "    submission_number=18\n",
    "    submission_df.index.name = 'id'\n",
    "    submission_df = submission_df.round(6)\n",
    "    submission_format_path = \"../data/givens/submission_format.csv\"\n",
    "    submission_format = pd.read_csv(submission_format_path, index_col=\"id\")\n",
    "\n",
    "\n",
    "    assert all(submission_df.index == submission_format.index)\n",
    "    assert all(submission_df.columns == submission_format.columns)\n",
    "\n",
    "    # Save submission_df for further use\n",
    "    submission_df_path = f\"../results/submissions/submission{submission_number}.csv\"\n",
    "    submission_df.to_csv(submission_df_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you submit update the submission score for logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if explore:\n",
    "     # ✨ Mannualy Log Test Results to W&B\n",
    "    wandb.log({\n",
    "        \"test_score\": 1.1210\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End your logging session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if explore:\n",
    "    # ✨ W&B: Mark the run as complete (Or wait until the end of notebook)\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dlfinal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
