{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to implement u-net background subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import wandb\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "Running on cuda...\n"
     ]
    }
   ],
   "source": [
    "# Choose device to run on\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "if(torch.backends.mps.is_available()):\n",
    "    device = \"mps\"\n",
    "elif(torch.cuda.is_available()):\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Running on {device}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wandb -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed value for repeatability\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)  # Python's random module\n",
    "torch.manual_seed(seed)  # PyTorch CPU/GPU seed\n",
    "np.random.seed(seed)  # NumPy random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start loading up the data\n",
    "\n",
    "# TODO: update base_path to point to wherever your data is stored\n",
    "base_path = \"../../Data/data/\"\n",
    "\n",
    "train_features = pd.read_csv(f\"{base_path}train_features.csv\", index_col=\"id\")\n",
    "test_features = pd.read_csv(f\"{base_path}test_features.csv\", index_col=\"id\")\n",
    "train_labels = pd.read_csv(f\"{base_path}train_labels.csv\", index_col=\"id\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 'filepath' column with the full path to each image\n",
    "# Subdirectories for train and test images\n",
    "train_images_path = os.path.join(base_path, \"train_features\")\n",
    "test_images_path = os.path.join(base_path, \"test_features\")\n",
    "\n",
    "train_features['filepath'] = train_features.index.map(\n",
    "    lambda img_id: os.path.join(train_images_path, f\"{img_id}.jpg\"))\n",
    "\n",
    "test_features['filepath'] = test_features.index.map(\n",
    "    lambda img_id: os.path.join(test_images_path, f\"{img_id}.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_labels = sorted(train_labels.columns.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start diverging from the \"standard\" example provided by the competition here. Let's pull out all the blank images from the train dataset. Then we'll test/train split on that for training the U-Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_training_labels = train_labels[train_labels[\"blank\"]==1]\n",
    "\n",
    "blank_training_images = train_features.loc[blank_training_labels.index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're only using one class here, this is more of an unsupervised activity than a supervised one. As such, we only have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(blank_training_images, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackgroundDataset(Dataset):\n",
    "\n",
    "    def __init__(self, train_features, transform = None, device=device):\n",
    "        self.data = train_features, \n",
    "        self.device = device,\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_id = self.data.index[index]\n",
    "        image = Image.open(self.data.iloc[index][\"filepath\"]).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        sample = {\"image_id\": image_id, \"image\": image}\n",
    "\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "\n",
    "background_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = BackgroundDataset(X_train, transform=background_transform, device=device)\n",
    "test_dataset =  BackgroundDataset(X_test, transform= background_transform, device=device)\n",
    "\n",
    "pin = False if device==\"cuda\" else True\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size = BATCH_SIZE, \n",
    "    shuffle = True,\n",
    "    pin_memory = pin\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = BackgroundDataset(X_train, transform=background_transform, device=device)\n",
    "test_dataset =  BackgroundDataset(X_test, transform= background_transform, device=device)\n",
    "\n",
    "\n",
    "# Choose batch size here:\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "pin = False if device==\"cuda\" else True\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size = BATCH_SIZE, \n",
    "    shuffle = True,\n",
    "    pin_memory = pin\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    pin_memory = pin\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, lets start working on building the U-Net itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guided by: https://github.com/milesial/Pytorch-UNet/blob/master/unet/unet_parts.py\n",
    "\n",
    "class DownConvolve(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.down = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels, self.out_channels, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(self.in_cannels, self.out_channels, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        def forward(self, x):\n",
    "             return self.down(x)\n",
    "\n",
    "class UpConvolve(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels, self.out_channels, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(self.in_channels, self.out_channels, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class UnetModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FinalProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
